{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Artificial Inteligence (CS550)**\n",
    "<br>\n",
    "Title: **Seminar №7**\n",
    "<br>\n",
    "Speaker: **Dr. Shota Tsiskaridze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\">Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Step 1: Data Gathering</h3>\n",
    "\n",
    "\n",
    "- Lets assume that that our goal is to **determine whether candidates would get admitted to a prestigious university or not**.\n",
    "\n",
    "\n",
    "- We have dataset containing **40 observations** where:\n",
    "  - the independent variables are:\n",
    "    - **GMAT** score: Graduate Management Admission Test, a scaled combination of your verbal and quantitative scaled scores. This test is used for admission to most MBA programs in the U.S. and Canada, as well as most English-language MBA programs in Europe.  \n",
    "    - **GPA** score: Grade Point Average, a system of judging a student's performance and is followed throughout the United States.\n",
    "    - Years of **work experience**.\n",
    "  - the dependent variables represents whether a person gets admitted or not:\n",
    "    - 1: Admitted\n",
    "    - 0: Rejected\n",
    "\n",
    "\n",
    "- This is how our dataset looks like:\n",
    "\n",
    "<img src=\"images/S7_Dataset.png\" width=\"500\" alt=\"Example\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Step 2: Importing the Required Packages</h3>\n",
    "\n",
    "- Lets import required Python packeges:\n",
    "  - **pandas** – used to create the DataFrame to capture the dataset in Python\n",
    "  - **sklearn** – used to build the logistic regression model in Python\n",
    "  - **seaborn** – used to create the Confusion Matrix\n",
    "  - **matplotlib** – used to display charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Step 3: Creating a Data Frame</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gmat  gpa  work_experience  admitted\n",
      "0    780  4.0                3         1\n",
      "1    750  3.9                4         1\n",
      "2    690  3.3                3         0\n",
      "3    710  3.7                5         1\n",
      "4    680  3.9                4         0\n",
      "5    730  3.7                6         1\n",
      "6    690  2.3                1         0\n",
      "7    720  3.3                4         1\n",
      "8    740  3.3                5         1\n",
      "9    690  1.7                1         0\n",
      "10   610  2.7                3         0\n",
      "11   690  3.7                5         1\n",
      "12   710  3.7                6         1\n",
      "13   680  3.3                4         0\n",
      "14   770  3.3                3         1\n",
      "15   610  3.0                1         0\n",
      "16   580  2.7                4         0\n",
      "17   650  3.7                6         1\n",
      "18   540  2.7                2         0\n",
      "19   590  2.3                3         0\n",
      "20   620  3.3                2         1\n",
      "21   600  2.0                1         0\n",
      "22   550  2.3                4         0\n",
      "23   550  2.7                1         0\n",
      "24   570  3.0                2         0\n",
      "25   670  3.3                6         1\n",
      "26   660  3.7                4         1\n",
      "27   580  2.3                2         0\n",
      "28   650  3.7                6         1\n",
      "29   660  3.3                5         1\n",
      "30   640  3.0                1         0\n",
      "31   620  2.7                2         0\n",
      "32   660  4.0                4         1\n",
      "33   660  3.3                6         1\n",
      "34   680  3.3                5         1\n",
      "35   650  2.3                1         0\n",
      "36   670  2.7                2         0\n",
      "37   580  3.3                1         0\n",
      "38   590  1.7                4         0\n",
      "39   690  3.7                5         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Step 4: Creating the Logistic Regression Method</h3>\n",
    "\n",
    "- First, lets denote independent variables as $\\mathbf{X}$ and the dependent variable as $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['gmat', 'gpa','work_experience']]\n",
    "y = df['admitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, we split our **data set** on **test set** and **training set**.\n",
    "\n",
    "- We set the **test size** to $0.25$, therefore the **model testing** will be based on **$25\\%$ of the dataset**, while the **model training** will be based on **$75\\%$ of the dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, we apply the **logistic regression method**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred = logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the **seaborn package** to get the **Confusion Matrix**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a543958be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)Finally, we apply the **logistic regression method**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can observe from the Confusion Matrix:\n",
    "  - **TP** = True Positive = 4;\n",
    "  - **TN** = True Negative = 4;\n",
    "  - **FP** = False Positive = 1;\n",
    "  - **FN** = False Negative = 1;\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the final part, we print the **Accuracy** of the model:\n",
    "\n",
    "  $$\\mathbf{Accuracy} = \\frac{\\mathbf{TP + TN}}{\\mathbf{Total}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall that our original dataset had 40 observations. Since we set the test size to $0.25$, then the confusion matrix displayed the results for **10 records**. \n",
    "\n",
    "- These are the 10 test records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gmat  gpa  work_experience\n",
      "22   550  2.3                4\n",
      "20   620  3.3                2\n",
      "25   670  3.3                6\n",
      "4    680  3.9                4\n",
      "10   610  2.7                3\n",
      "15   610  3.0                1\n",
      "28   650  3.7                6\n",
      "11   690  3.7                5\n",
      "18   540  2.7                2\n",
      "29   660  3.3                5\n",
      "[0 0 1 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print (X_test) #test dataset\n",
    "print (y_pred) #predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the actual dataset we see that for the test data, we got the correct results 8 out of 10 times:\n",
    "\n",
    "<img src=\"images/S7_Accuracy.png\" width=\"700\" alt=\"Example\" />\n",
    "\n",
    "- This is matching with the **accuracy** level of $80\\%$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Step 4: Checking the Prediction for a New Data Set</h3>\n",
    "\n",
    "- Let’s assume that we have a new data set with **5 new candidates**:\n",
    "\n",
    "| gmat | gpa | work_experience |\n",
    "|------|-----|-----------------|\n",
    "| 590  | 2   | 3               |\n",
    "| 740  | 3.7 | 4               |\n",
    "| 680  | 3.3 | 6               |\n",
    "| 610  | 2.3 | 1               |\n",
    "| 710  | 3   | 5               |\n",
    "\n",
    "- Our goal is to predict whether the **new candidates will get admitted or not**, using the **existing logistic regression model**.\n",
    "\n",
    "- For this, lets create a second DataFrame called df2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_candidates = {'gmat': [590,740,680,610,710],\n",
    "                  'gpa': [2,3.7,3.3,2.3,3],\n",
    "                  'work_experience': [3,4,6,1,5]\n",
    "                  }\n",
    "\n",
    "df2 = pd.DataFrame(new_candidates,columns= ['gmat', 'gpa','work_experience'])<h3 align=\"center\">Step 3: Creating a Data Frame</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And here is the complete code to get the prediction for the **5 new candidates**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gmat  gpa  work_experience\n",
      "0   590  2.0                3\n",
      "1   740  3.7                4\n",
      "2   680  3.3                6\n",
      "3   610  2.3                1\n",
      "4   710  3.0                5\n",
      "[0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "\n",
    "\n",
    "X = df[['gmat', 'gpa','work_experience']]\n",
    "y = df['admitted']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)  #in this case, you may choose to set the test_size=0. You should get the same prediction here\n",
    "\n",
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "new_candidates = {'gmat': [590,740,680,610,710],\n",
    "                  'gpa': [2,3.7,3.3,2.3,3],\n",
    "                  'work_experience': [3,4,6,1,5]\n",
    "                  }\n",
    "\n",
    "df2 = pd.DataFrame(new_candidates,columns= ['gmat', 'gpa','work_experience'])\n",
    "y_pred=logistic_regression.predict(df2)\n",
    "\n",
    "print (df2)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Therefore, tt is expected that the **first and fourth candidates will not be admitted**, while **other candidates will be admitted**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">End of Seminar</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
