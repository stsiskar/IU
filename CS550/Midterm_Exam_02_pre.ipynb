{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Artificial Inteligence (CS550)**\n",
    "<br>\n",
    "Date: **1 May 2020**\n",
    "<br>\n",
    "Title: **Preparation for the Midterm Exam № 2**\n",
    "\n",
    "The exam will be evaluated at a maximum **20 points**. Each problem is **5 points**. \n",
    "Each subtask is  **1 point**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem 1: Multi-Class Cofusion Matrix</h3>\n",
    "\n",
    "Problem will consist of $3\\times 3$ Confusion Matrix.\n",
    "\n",
    "Usefull links for this material:\n",
    "<br>\n",
    "https://dev.to/overrideveloper/understanding-the-confusion-matrix-264i\n",
    "<br>\n",
    "https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "\n",
    "The main goal of this problem to get familiar with Confusion Matrix terminology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem 2: The Perceptron Algorithm</h3>\n",
    "\n",
    "- Lets consider the **AND Gate** problem. \n",
    "\n",
    "- The **Gate Opens** if and only if **both inputs are true**.\n",
    "\n",
    "|              | $x_1$ | $x_2$ | $t$ |\n",
    "|:------------:|:---:|:---:|:---:|\n",
    "|$\\mathbf{x}_1$|  0  |  0  |  0  |\n",
    "|$\\mathbf{x}_1$|  0  |  1  |  0  |\n",
    "|$\\mathbf{x}_1$|  1  |  0  |  0  |\n",
    "|$\\mathbf{x}_1$|  1  |  1  |  1  |\n",
    "\n",
    "- Therefore, we have two clases ($K = 2$) and target values are $t \\in \\{0, 1\\}$\n",
    "\n",
    "**Problem statement**. Perform the perceptron algorithm, assuming that: \n",
    "- The initial weights are equal to **inital weights** $w_1 = 0.9$ and $w_2 = 0.9$.\n",
    "- The **activation threshold** $T$ is equal to $0.5$.\n",
    "- The **learning rate** $\\eta$ is equal to $0.5$.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "Usefull link: https://www.youtube.com/watch?v=tEkjw0hNN_w\n",
    "\n",
    "<img src=\"images/preME2_P2.png\" width=\"400\" alt=\"Example\" />\n",
    "\n",
    "**First Round**:\n",
    "\n",
    "- $1^{st}$ instance to the perceptron: \n",
    "\n",
    "  $\\mathbf{x}_1 = (0, 0)$;\n",
    "\n",
    "  $\\Sigma = w_1 x_1  + w_2 x_2 = 0.9 \\cdot 0 + 0.9 \\cdot 0 = 0$;\n",
    "  \n",
    "  Compare with activation threshold $\\Sigma < T$, therefore, **activation** unit would **return 0**.\n",
    "  \n",
    "  The output of this instance **should be 0**, so **we will not update weights** because there is **no error** in this case.\n",
    "  \n",
    "  \n",
    "- $2^{nd}$ instance to the perceptron: \n",
    "\n",
    "  $\\mathbf{x}_2 = (0, 1)$;\n",
    "\n",
    "  $\\Sigma = w_1 x_1  + w_2 x_2 = 0.9 \\cdot 0 + 0.9 \\cdot 1 = 0.9$;\n",
    "  \n",
    "  Compare with activation threshold $\\Sigma > T$, therefore, **activation** unit would **return 1**.\n",
    "  \n",
    "  The output of this instance **should be 0**, so **we will update weights**:\n",
    "  \n",
    "  $\\epsilon = actual - prediction = -1$\n",
    "  \n",
    "  $w_1^{(updated)} = w_1 + \\eta \\cdot \\epsilon = 0.9 + 0.5 \\cdot (-1) = 0.4$;\n",
    "  \n",
    "  $w_2^{(updated)} = w_2 + \\eta \\cdot \\epsilon = 0.9 + 0.5 \\cdot (-1) = 0.4$.\n",
    "\n",
    "\n",
    "- $3^{rd}$ instance to the perceptron: \n",
    "\n",
    "  $\\mathbf{x}_3 = (1, 0)$;\n",
    "\n",
    "  $\\Sigma = w_1 x_1  + w_2 x_2 = 0.4 \\cdot 1 + 0.4 \\cdot 0 = 0.4$;\n",
    "  \n",
    "  Compare with activation threshold $\\Sigma < T$, therefore, **activation** unit would **return 0**.\n",
    "  \n",
    "  The output of this instance **should be 0**, so **we will not update weights** because there is **no error** in this case.\n",
    "\n",
    "\n",
    "- $4^{th}$ instance to the perceptron: \n",
    "\n",
    "  $\\mathbf{x}_4 = (1, 1)$;\n",
    "\n",
    "  $\\Sigma = w_1 x_1  + w_2 x_2 = 0.4 \\cdot 1 + 0.4 \\cdot 1 = 0.8$;\n",
    "  \n",
    "  Compare with activation threshold $\\Sigma > T$, therefore, **activation** unit would **return 1**.\n",
    "  \n",
    "  The output of this instance **should be 1**, so **we will not update weights** because there is **no error** in this case.\n",
    "  \n",
    "\n",
    "**Second Round**:\n",
    "\n",
    "- In previous round, we’ve used previous weight values for the $1^{st}$ instance and it was classified correctly.\n",
    "\n",
    "- Let’s apply feed forward for the new weight values.\n",
    "\n",
    "\n",
    "- $1^{st}$ instance to the perceptron: \n",
    "\n",
    "  $\\mathbf{x}_1 = (0, 0)$;\n",
    "\n",
    "  $\\Sigma = w_1 x_1  + w_2 x_2 = 0.4 \\cdot 0 + 0.4 \\cdot 0 = 0$;\n",
    "  \n",
    "  Compare with activation threshold $\\Sigma < T$, therefore, **activation** unit would **return 0**.\n",
    "  \n",
    "  The output of this instance **should be 0**, so **we will not update weights** because there is **no error** in this case.  \n",
    "  \n",
    "  \n",
    "- $2^{nd}$ instance to the perceptron: \n",
    "\n",
    "  $\\mathbf{x}_1 = (0, 1)$;\n",
    "\n",
    "  $\\Sigma = w_1 x_1  + w_2 x_2 = 0.4 \\cdot 0 + 0.4 \\cdot 1 = 0$;\n",
    "  \n",
    "  Compare with activation threshold $\\Sigma < T$, therefore, **activation** unit would **return 0**.\n",
    "  \n",
    "  The output of this instance **should be 0**, so **we will not update weights** because there is **no error** in this case.  \n",
    "    \n",
    "- We’ve applied **feed forward** calculation for **$3^{rd}$ and $4^{th}$ instances**  and they were **classified correctly**.\n",
    "\n",
    "\n",
    "Luckily, we can **find the best weights** in **2 rounds**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem 3: $K$-means Algorithm</h3>\n",
    "\n",
    "- Lets assume that our **input space** consist of **data points** $\\mathbf{x}_n = (x_n, y_n)$, where $n = 1, ..., N$. \n",
    "\n",
    "- **Number of Clusters** is equal to $K = 2$.\n",
    "\n",
    "|                  | $x$ | $y$ |\n",
    "|:----------------:|:---:|:---:|\n",
    "| $\\mathbf{x}_1$   |  1  |  1  |\n",
    "| $\\mathbf{x}_2$   |  1  |  2  |\n",
    "| $\\mathbf{x}_3$   |  2  |  2  |\n",
    "| $\\mathbf{x}_4$   |  2  |  3  |\n",
    "| $\\mathbf{x}_5$   |  3  |  1  |\n",
    "| $\\mathbf{x}_6$   |  3  |  3  |\n",
    "| $\\mu_1$          |  2  |  2  |\n",
    "| $\\mu_2$          |  3  |  3  |\n",
    "\n",
    "**Problem statement**:\n",
    "\n",
    "1. **Plot the data points** on the $(X,Y)$ coordinate plane.\n",
    "2. **Calculate the distance** between the **each data point** and the centers of **each clusters** using the Euclidean distance\n",
    "  $$d(\\mathbf{x}, \\mu) = \\sqrt{(x - {\\mu}_x)^2 + (y - {\\mu}_y)^2},$$\n",
    "  where $\\mathbf{x}$ is some data point and $\\mu$ is the center of some cluster.\n",
    "3. **Assign** each **data point** to the corresponding **cluster**.\n",
    "4. **Recalculate** the **new centers position** of the **clusters**  $k = 1, 2$:\n",
    "\n",
    "  $$\\mu_k^{(new)} = \\frac{\\sum_{n=1}^{N} r_{nk} \\| \\mathbf{x}_n - \\mathbf{\\mu}_k\\|^2}{\\sum_{n=1}^{N} r_{nk}}.$$\n",
    "   \n",
    "  Here $r_{nk} \\in \\{0,1 \\}$ is a binary indicator variables, where $k = 1, . . . , K $ describing which of the $K$ clusters the data point $\\mathbf{x}_n$ is assigned to. If data point $\\mathbf{x}_n$ is assigned to cluster $k$ then $r_{nk} = 1$, and $r_{nj} = 0$ for $j\\neq k$.\n",
    "  \n",
    "5. **Repeat steps 2 and 4** until the **algorithm converge**.\n",
    "\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "1. <img src=\"images/preME2_P3.png\" width=\"300\" alt=\"Example\" />\n",
    "\n",
    "\n",
    "2. Lets calculate the distances between each data point and each cluster center:\n",
    "\n",
    "  $d(\\mathbf{x}_1, \\mu_1) = \\sqrt{(2-1)^2 + (2-1)^2} = \\sqrt{2}$ &emsp; < &emsp; $d(\\mathbf{x}_1, \\mu_2) = \\sqrt{(3-1)^2 + (3-1)^2} = 2\\sqrt{2}$\n",
    "\n",
    "  $d(\\mathbf{x}_2, \\mu_1) = \\sqrt{(2-1)^2 + (2-2)^2} = \\sqrt{1}$ &emsp; < &emsp; $d(\\mathbf{x}_2, \\mu_2) = \\sqrt{(3-1)^2 + (3-2)^2} = \\sqrt{5}$\n",
    "  \n",
    "  $d(\\mathbf{x}_3, \\mu_1) = \\sqrt{(2-2)^2 + (2-2)^2} = \\sqrt{0}$ &emsp; < &emsp; $d(\\mathbf{x}_3, \\mu_2) = \\sqrt{(3-2)^2 + (3-2)^2} = \\sqrt{2}$\n",
    "    \n",
    "  $d(\\mathbf{x}_4, \\mu_1) = \\sqrt{(2-2)^2 + (2-3)^2} = \\sqrt{1}$ &emsp; = &emsp; $d(\\mathbf{x}_4, \\mu_2) = \\sqrt{(3-2)^2 + (3-3)^2} = \\sqrt{1}$\n",
    "    \n",
    "  $d(\\mathbf{x}_5, \\mu_1) = \\sqrt{(2-3)^2 + (2-1)^2} = \\sqrt{2}$ &emsp; < &emsp; $d(\\mathbf{x}_5, \\mu_2) = \\sqrt{(3-3)^2 + (3-1)^2} = \\sqrt{4}$\n",
    "  \n",
    "  $d(\\mathbf{x}_6, \\mu_1) = \\sqrt{(2-3)^2 + (2-3)^2} = \\sqrt{2}$ &emsp; > &emsp; $d(\\mathbf{x}_6, \\mu_2) = \\sqrt{(3-3)^2 + (3-3)^2} = \\sqrt{0}$\n",
    "\n",
    "\n",
    "3. Lets assing the data points to the closest data center (in case of equal distances, choose random cluster center):\n",
    "\n",
    "  $C_1 = \\{\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3, \\mathbf{x}_4\\}$;\n",
    "  \n",
    "  $C_2 = \\{\\mathbf{x}_4, \\mathbf{x}_6\\}$.\n",
    "  \n",
    "  \n",
    "4. Lets recalculate the new cluster centers:\n",
    "\n",
    "  $\\mu_1^1 = \\left ( \\frac{1 + 1 + 2 + 3}{4}, \\frac{1 + 2 + 2 + 1}{4} \\right ) = \\left ( \\frac{7}{4}, \\frac{6}{4} \\right )$\n",
    "  \n",
    "  $\\mu_2^1 = \\left ( \\frac{2 + 3}{2}, \\frac{3 + 3}{2} \\right ) = \\left ( \\frac{5}{2}, \\frac{6}{2} \\right )$\n",
    "  \n",
    "  \n",
    "5. Repeat the steps 2, 3, 4. **Validate that cluster does not change!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem 4: Decision Tree</h3>\n",
    "\n",
    "\n",
    "Problem will consist of classification problem which solution follows closely the Decision Tree algorithm described here:\n",
    "\n",
    "https://medium.com/datadriveninvestor/decision-tree-algorithm-with-hands-on-example-e6c2afb40d38\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706311"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "S = - ( 9/14 * np.log2(9/14) + 5/14 * np.log2(5/14) )\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935361388961918"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Ent(x, y):\n",
    "    if x == 0 or y == 0:\n",
    "        z = 0\n",
    "    else:\n",
    "        z = -( x / (x + y) * np.log2(x / (x + y)) + y / (x + y) * np.log2(y / (x + y)))\n",
    "    return z\n",
    "\n",
    "ES = 5/14 * Ent(3,2) + 4/14 * Ent(4, 0) + 5/14 * Ent(2,3)\n",
    "ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24674981977443933"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S - ES"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
